# 数据完整性协议 (Data Integrity Protocol)

> **版本**: v2.0  
> **创建日期**: 2025-12-07  
> **适用范围**: GithubLedger 所有数据处理流程  
> **状态**: Active  

---

## 核心原则

### 1. 真实性原则 (Truth Principle) ⭐⭐⭐

**系统不得编造任何不存在的数据。**

- **禁止行为**：
  - ❌ 为缺失的时间字段自动补全 `00:00:00`
  - ❌ 推测用户可能的消费类别并直接填入
  - ❌ 修改原始金额数值（包括四舍五入）
  - ❌ 合并后创造不存在的"商户名称"

- **允许行为**：
  - ✅ 保留原始字段为 `null` 或空值
  - ✅ 在独立的 `confidence_score` 字段标注不确定性
  - ✅ 使用 `tags` 系统标记推测性分类（而非直接写入 `category`）

### 2. 精度适配原则 (Precision Matching) ⭐⭐⭐

**输出数据的精度不得高于输入数据的精度。**

- **时间字段**：
  - 若源数据为 `2025-03-15` (仅日期)，转换后必须保持 `2025-03-15`，不得补全为 `2025-03-15 00:00:00`
  - 若源数据为 `2025-03-15 14:30:45` (含时分秒)，必须完整保留

- **金额字段**：
  - 若源数据为 `20`，不得自动格式化为 `20.00`（除非用户配置明确要求）
  - 若源数据为 `20.5`，必须保持，不得截断为 `21`

### 3. 交易类型筛选原则 (Transaction Filtering) ⭐⭐⭐

**系统必须严格区分"消费记录"与"资金流动"。**

默认情况下，以下类型的交易**不应**被导入标准数据库：

- ❌ 还款类交易（信用卡还款、贷款还款）
- ❌ 转账类交易（给他人转账、内部账户转移）
- ❌ 红包类交易（微信红包收发）
- ❌ 充值/提现（支付宝余额充值、银行卡提现）

**例外情况**：用户在 `UserProfile` 中明确声明 `include_transfers: true` 时可放行。

### 4. 数据来源追溯原则 (Source Traceability) ⭐⭐

**每条记录必须能追溯到其来源文件和原始状态。**

- **必需字段**：
  - `source_file`: 来源文件名（如 `wechat_bill_202503.csv`）
  - `original_row`: 原始数据的 JSON 快照
  - `import_timestamp`: 导入时间（ISO8601 格式）

- **目的**：
  - 当用户质疑数据时，能快速回溯原始文件
  - 支持"撤销导入"功能
  - 便于审计和调试

---

## 处理流程质量检查点

### 阶段 1: 数据摄入 (Ingestion)

- [ ] 文件编码正确识别（UTF-8/GBK/GB2312）
- [ ] 原始数据备份已创建
- [ ] 文件路径记录在日志中
- [ ] 行数统计与原文件一致

### 阶段 2: 列映射 (Column Mapping)

- [ ] AI 已识别所有必需字段（日期、金额、商户）
- [ ] 用户确认了 AI 的映射建议
- [ ] 映射规则已保存到 `UserProfile`
- [ ] 无强制类型转换错误（如将文本强转为数字）

### 阶段 3: 数据清洗 (Cleaning)

- [ ] 非消费类交易已按规则排除
- [ ] 时间格式符合精度适配原则
- [ ] 金额字段无异常值（负数/空值/非数字）
- [ ] 清洗日志记录了所有删除/修改操作

### 阶段 4: 语义分拣 (Semantic Processing)

- [ ] AI 提取的实体（商户/分类）标注了可信度分数
- [ ] 低可信度记录（<0.8）已标红提示人工复核
- [ ] 分类维度已拆解（不混淆"对象"与"类型"）
- [ ] 标签系统正确应用（如 `[女儿, 教育]`）

### 阶段 5: 去重 (Deduplication)

- [ ] 去重算法使用了多字段匹配（金额+时间+商户）
- [ ] 用户确认了去重结果预览
- [ ] 保留了所有被去重记录的日志
- [ ] 重复记录标记了 `duplicate_of` 字段

### 阶段 6: 输出验证 (Output Validation)

- [ ] 输出记录数在合理范围内（无异常丢失）
- [ ] 所有 `StandardRecord` 字段符合 Schema 定义
- [ ] CSV 文件可被 Excel/Pandas 正常读取
- [ ] 生成了处理报告（包含统计数据和警告信息）

---

## 错误分级与响应

### 🔴 严重错误 (Critical) - 必须中止处理

- **编造数据**：系统为缺失字段自动填充了不存在的值
- **数据泄露**：包含了被明确排除的交易类型（如红包、转账）
- **精度破坏**：将低精度数据提升为高精度（如日期变时间戳）
- **丢失溯源**：记录无法追溯到原始文件

**响应**：立即停止处理，回滚已导入数据，显示详细错误报告。

### 🟡 警告错误 (Warning) - 需要人工确认

- **分类不确定**：AI 可信度 < 0.8 的分类结果
- **异常金额**：单笔交易 > 5000 元或 < 0.1 元
- **商户名称差异**：同一商户存在多种表示（如"瑞幸"/"luckin coffee"）
- **时间跳跃**：记录时间跨度出现大段空白（如连续 30 天无数据）

**响应**：在预览界面高亮显示，要求用户确认后再继续。

### 🟢 提示信息 (Info) - 可接受

- **未分类**：少量记录（<5%）无法自动分类，标记为 `category: "未分类"`
- **商户简化**：AI 将冗长商户名简化（如"湖南湘潭中心医院" -> "中心医院"）
- **标签建议**：AI 建议添加标签但未自动应用

**响应**：记录在日志中，不阻断流程。

---

## 验证通过标准

处理结果必须同时满足：

- ✅ **严重错误数 = 0**
- ✅ **警告错误比例 < 5%**
- ✅ **数据完整性 > 95%**（记录数/原始数据行数）
- ✅ **必需字段完整率 = 100%**（date, amount, source_file）
- ✅ **溯源可用性 = 100%**（每条记录都能追溯）

---

## 修正指令模板

### 严重错误修正

```text
检测到严重错误：[具体错误类型]
受影响记录数：[N]

详细问题：
1. [具体描述]
2. [具体描述]

要求系统：
1. 回滚本次导入
2. 修正处理逻辑
3. 重新执行并生成对比报告
```

### 警告确认

```text
以下记录存在不确定性，请确认：

[列出记录]

选项：
1. 接受 AI 建议并继续
2. 手动修正后再导入
3. 将这些记录标记为"待人工处理"
```

---

## 最终确认清单

在将数据标记为"已就绪"前，必须确认：

- [ ] 所有关键质量检查点已通过
- [ ] 用户已查看并确认预览结果
- [ ] 处理报告已生成并保存
- [ ] 数据备份已创建
- [ ] 原始文件已归档到 `data/raw/` 目录
- [ ] 导入日志已写入系统数据库

---

**签署**：符合本协议的数据才能被标记为 `status: "validated"`，否则必须保持 `status: "pending_review"`。
